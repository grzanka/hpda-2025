{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002c19a8",
   "metadata": {},
   "source": [
    "# Dask Lazy Evaluation and Task Graphs\n",
    "\n",
    "In this notebook, we'll explore:\n",
    "\n",
    "- **Lazy Evaluation Strategies**: Building computation graphs vs immediate execution\n",
    "- **Task Graph Optimization**: How Dask optimizes complex operations before execution  \n",
    "- **Memory-Efficient Computing**: Processing larger-than-memory datasets through intelligent partitioning\n",
    "- **Distributed Aggregations**: Scaling groupby and statistical operations across multiple cores\n",
    "- **Performance Debugging**: Visualizing and optimizing computation graphs\n",
    "\n",
    "### The Dask Computational Model\n",
    "\n",
    "Dask's power comes from its sophisticated approach to computation:\n",
    "\n",
    "1. **Lazy Evaluation**: Operations build a task graph without immediate execution\n",
    "2. **Graph Optimization**: Dask optimizes the entire computation pipeline before running\n",
    "3. **Intelligent Scheduling**: Tasks are distributed efficiently across available resources  \n",
    "4. **Memory Management**: Only necessary data partitions are loaded into memory\n",
    "5. **Fault Tolerance**: Failed tasks can be recomputed without restarting entire workflows\n",
    "\n",
    "### Why This Matters for HPDA\n",
    "\n",
    "**Traditional pandas approach:**\n",
    "```python\n",
    "df = pd.read_csv('large_file.csv')      # Load entire dataset\n",
    "result = df[df.col > 0].groupby('id').mean()  # Process in memory\n",
    "```\n",
    "\n",
    "**Dask approach:**\n",
    "```python\n",
    "df = dd.read_csv('large_file.csv')      # Create lazy DataFrame\n",
    "result = df[df.col > 0].groupby('id').mean()  # Build computation graph\n",
    "final = result.compute()                # Execute optimized graph\n",
    "```\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you'll understand:\n",
    "- When to use `.compute()` vs keeping operations lazy\n",
    "- How to inspect and optimize Dask computation graphs\n",
    "- Memory-efficient strategies for large-scale aggregations\n",
    "- Performance debugging techniques for distributed computing\n",
    "\n",
    "Let's explore these concepts with our meteorological dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac16ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import dask.dataframe as dd\n",
    "import psutil\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196ea388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available RAM: 4.24 GB\n"
     ]
    }
   ],
   "source": [
    "# print amount of available RAM memory\n",
    "print(f\"Available RAM: {psutil.virtual_memory().available / (1024 ** 3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b986829",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b90fb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pathlib create directory called meteo\n",
    "data_raw_path = pathlib.Path(\"meteo\") / \"meteo_dask.h5\"\n",
    "data_raw_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74977fa",
   "metadata": {},
   "source": [
    "### Loading Distributed Data with HDF5\n",
    "\n",
    "`dd.read_hdf()` creates a lazy Dask DataFrame:\n",
    "\n",
    "**Key Advantages of HDF5 for Dask Computing:**\n",
    "- **Efficient chunking**: Data automatically partitioned for parallel processing\n",
    "- **Metadata preservation**: Column types, compression info maintained\n",
    "- **Fast random access**: Enables efficient filtering and subsetting operations\n",
    "- **Cross-platform compatibility**: Works identically on different systems\n",
    "\n",
    "**Memory Efficiency**: This operation uses minimal memory - no data is loaded until computation is triggered with `.compute()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c628f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_hdf(data_raw_path, key='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46e0bf",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "The `.head()` method is special in Dask - it's one of the few operations that **automatically triggers computation**:\n",
    "\n",
    "**Why `.head()` is eager:**\n",
    "- **Development workflow**: Developers need immediate feedback during exploration\n",
    "- **Small result size**: First few rows fit easily in memory\n",
    "- **Safety mechanism**: Prevents accidentally loading entire datasets during exploration\n",
    "\n",
    "**Performance Insight**: `.head()` only reads enough data to return the requested rows, making it extremely efficient even on terabyte-scale datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bb1ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "Time",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "TempOut",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TempHi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TempLow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HumOut",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DewPt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindSpeed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindDir",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "WindRun",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindSpeedHi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindDirHi",
         "rawType": "string",
         "type": "string"
        },
        {
         "name": "WindChill",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HeatIndex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "THWIndex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "THSWIndex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Bar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Rain",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RainRate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SolarRad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SolarEnergy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SolarRadHi",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "UVIndex",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "UVDose",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "UVIndexHi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HeatDD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CoolDD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TempIn",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HumIn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DewPtIn",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HeatIn",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ET",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindSamp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindTx",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ISSRecept",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ArcInt",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9e2751f2-c217-41a9-b684-8afd402bdd90",
       "rows": [
        [
         "0",
         "24-12-29",
         "0:30",
         "0.4",
         "0.4",
         "0.3",
         "98",
         "0.1",
         "0.0",
         "NE",
         "0.0",
         "0.9",
         "NE",
         "0.4",
         "0.4",
         "0.4",
         "-1.7",
         "993.2",
         "0.0",
         "0.0",
         "0",
         "0.0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.374",
         "0.0",
         "18.4",
         "30",
         "0.5",
         "16.4",
         "0.0",
         "699.0",
         "1.0",
         "100.0",
         "30.0"
        ],
        [
         "1",
         "24-12-29",
         "1:00",
         "0.1",
         "0.3",
         "-0.1",
         "98",
         "-0.2",
         "0.0",
         "NE",
         "0.0",
         "0.4",
         "NE",
         "0.1",
         "0.1",
         "0.1",
         "-2.1",
         "992.9",
         "0.0",
         "0.0",
         "0",
         "0.0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.381",
         "0.0",
         "18.4",
         "30",
         "0.5",
         "16.4",
         "0.0",
         "699.0",
         "1.0",
         "100.0",
         "30.0"
        ],
        [
         "2",
         "24-12-29",
         "1:30",
         "-0.2",
         "-0.1",
         "-0.3",
         "98",
         "-0.5",
         "0.0",
         "NE",
         "0.0",
         "0.9",
         "NE",
         "-0.2",
         "-0.2",
         "-0.2",
         "-2.3",
         "992.8",
         "0.0",
         "0.0",
         "0",
         "0.0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.387",
         "0.0",
         "18.3",
         "30",
         "0.4",
         "16.4",
         "0.0",
         "699.0",
         "1.0",
         "100.0",
         "30.0"
        ],
        [
         "3",
         "24-12-29",
         "2:00",
         "-0.3",
         "-0.3",
         "-0.4",
         "98",
         "-0.6",
         "0.0",
         "NE",
         "0.0",
         "0.9",
         "NE",
         "-0.3",
         "-0.3",
         "-0.3",
         "-2.5",
         "992.8",
         "0.0",
         "0.0",
         "0",
         "0.0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.389",
         "0.0",
         "18.3",
         "30",
         "0.4",
         "16.3",
         "0.0",
         "700.0",
         "1.0",
         "100.0",
         "30.0"
        ],
        [
         "4",
         "24-12-29",
         "2:30",
         "-0.5",
         "-0.4",
         "-0.6",
         "98",
         "-0.8",
         "0.0",
         "NE",
         "0.0",
         "0.9",
         "NE",
         "-0.5",
         "-0.5",
         "-0.5",
         "-2.7",
         "992.7",
         "0.0",
         "0.0",
         "0",
         "0.0",
         "0",
         "0.0",
         "0.0",
         "0.0",
         "0.392",
         "0.0",
         "18.3",
         "30",
         "0.4",
         "16.3",
         "0.0",
         "701.0",
         "1.0",
         "100.0",
         "30.0"
        ]
       ],
       "shape": {
        "columns": 36,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TempOut</th>\n",
       "      <th>TempHi</th>\n",
       "      <th>TempLow</th>\n",
       "      <th>HumOut</th>\n",
       "      <th>DewPt</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDir</th>\n",
       "      <th>WindRun</th>\n",
       "      <th>...</th>\n",
       "      <th>CoolDD</th>\n",
       "      <th>TempIn</th>\n",
       "      <th>HumIn</th>\n",
       "      <th>DewPtIn</th>\n",
       "      <th>HeatIn</th>\n",
       "      <th>ET</th>\n",
       "      <th>WindSamp</th>\n",
       "      <th>WindTx</th>\n",
       "      <th>ISSRecept</th>\n",
       "      <th>ArcInt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24-12-29</td>\n",
       "      <td>0:30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>98</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24-12-29</td>\n",
       "      <td>1:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24-12-29</td>\n",
       "      <td>1:30</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24-12-29</td>\n",
       "      <td>2:00</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24-12-29</td>\n",
       "      <td>2:30</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  Time  TempOut  TempHi  TempLow  HumOut  DewPt  WindSpeed WindDir  \\\n",
       "0  24-12-29  0:30      0.4     0.4      0.3      98    0.1        0.0      NE   \n",
       "1  24-12-29  1:00      0.1     0.3     -0.1      98   -0.2        0.0      NE   \n",
       "2  24-12-29  1:30     -0.2    -0.1     -0.3      98   -0.5        0.0      NE   \n",
       "3  24-12-29  2:00     -0.3    -0.3     -0.4      98   -0.6        0.0      NE   \n",
       "4  24-12-29  2:30     -0.5    -0.4     -0.6      98   -0.8        0.0      NE   \n",
       "\n",
       "   WindRun  ...  CoolDD TempIn  HumIn  DewPtIn  HeatIn   ET  WindSamp  WindTx  \\\n",
       "0      0.0  ...     0.0   18.4     30      0.5    16.4  0.0     699.0     1.0   \n",
       "1      0.0  ...     0.0   18.4     30      0.5    16.4  0.0     699.0     1.0   \n",
       "2      0.0  ...     0.0   18.3     30      0.4    16.4  0.0     699.0     1.0   \n",
       "3      0.0  ...     0.0   18.3     30      0.4    16.3  0.0     700.0     1.0   \n",
       "4      0.0  ...     0.0   18.3     30      0.4    16.3  0.0     701.0     1.0   \n",
       "\n",
       "   ISSRecept  ArcInt  \n",
       "0      100.0    30.0  \n",
       "1      100.0    30.0  \n",
       "2      100.0    30.0  \n",
       "3      100.0    30.0  \n",
       "4      100.0    30.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cad9e4",
   "metadata": {},
   "source": [
    "### Dataset Size Information\n",
    "\n",
    "`len(df)` demonstrates Dask's intelligent optimization:\n",
    "\n",
    "**Under the hood:** Dask reads only the **metadata** from each partition to determine row counts, without loading actual data. This makes length calculation extremely fast even for massive datasets.\n",
    "\n",
    "**Distributed Challenge**: Unlike pandas, calculating exact lengths in distributed systems requires coordination between partitions, but Dask optimizes this through metadata caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ce86a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14492"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2a466",
   "metadata": {},
   "source": [
    "## Lazy vs Eager Evaluation: Understanding Computation Graphs\n",
    "\n",
    "This line creates a **computation graph** without executing it:\n",
    "\n",
    "```python\n",
    "df[df.HumOut > 0].TempOut.mean()\n",
    "```\n",
    "\n",
    "**Task Graph Components:**\n",
    "1. **Filter Operation**: `df.HumOut > 0` - creates boolean mask across all partitions\n",
    "2. **Subsetting**: `df[...]` - applies filter to DataFrame  \n",
    "3. **Column Selection**: `.TempOut` - selects specific column from filtered data\n",
    "4. **Aggregation**: `.mean()` - computes mean across all partitions\n",
    "\n",
    "**Memory Advantage**: This entire chain uses **zero additional memory** until `.compute()` is called!\n",
    "\n",
    "### The Power of Lazy Evaluation\n",
    "\n",
    "**Lazy operations return Dask objects:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68d3d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask_expr.expr.Scalar: expr=((Filter(frame=ArrowStringConversion(frame=FromMapProjectable(a26c2d6)), predicate=ArrowStringConversion(frame=FromMapProjectable(a26c2d6))['HumOut'] > 0))['TempOut']).mean(), dtype=float64>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.HumOut > 0].TempOut.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5742e",
   "metadata": {},
   "source": [
    "### Triggering Computation with .compute()\n",
    "\n",
    "**Now the magic happens!** `.compute()` triggers execution of the entire task graph:\n",
    "\n",
    "**Optimization Process:**\n",
    "1. **Graph Analysis**: Dask analyzes the computation graph for optimization opportunities\n",
    "2. **Task Scheduling**: Operations are distributed across available CPU cores  \n",
    "3. **Predicate Pushdown**: Filtering is applied as early as possible to minimize data movement\n",
    "4. **Parallel Execution**: Each partition is processed independently\n",
    "5. **Result Aggregation**: Final results are combined from all partitions\n",
    "\n",
    "**Performance Comparison:**\n",
    "- **Pandas equivalent**: Would load entire dataset, then filter, then compute mean\n",
    "- **Dask advantage**: Only processes relevant data, parallelizes across cores\n",
    "\n",
    "**Memory Usage**: Notice that only the final scalar result (mean temperature) is returned to memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8c796f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(12.737954592505695)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.HumOut > 0].TempOut.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd632b",
   "metadata": {},
   "source": [
    "## Computation Graph Visualization and Debugging\n",
    "\n",
    "### Visualizing Task Graphs for Performance Optimization\n",
    "\n",
    "**Uncomment the line below to see the computation graph visualization:**\n",
    "\n",
    "```python\n",
    "df[df.HumOut > 0].TempOut.mean().visualize(engine='cytoscape')\n",
    "```\n",
    "\n",
    "**Graph Visualization Benefits:**\n",
    "- **Identify bottlenecks**: Spot operations that require data shuffling between partitions\n",
    "- **Optimize workflows**: Reorder operations to minimize memory usage and computation time\n",
    "- **Debug performance**: Understand why certain operations are slow\n",
    "- **Educational value**: Visualize how Dask breaks down complex operations\n",
    "\n",
    "**Visualization Engines:**\n",
    "- **`'cytoscape'`**: Interactive web-based visualization (requires jupyter extensions)\n",
    "- **`'graphviz'`**: Static PNG/SVG output (requires graphviz installation)\n",
    "- **Built-in matplotlib**: Basic visualization for simple graphs\n",
    "\n",
    "**HPDA Pro Tip**: Always visualize computation graphs for complex operations to understand performance characteristics before running on production data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f5361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df.HumOut > 0].TempOut.mean().visualize(engine='cytoscape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c08295",
   "metadata": {},
   "source": [
    "## Advanced Aggregation Patterns\n",
    "\n",
    "GroupBy operations are among the most complex in distributed computing:\n",
    "\n",
    "**Challenges with Distributed GroupBy:**\n",
    "- **Data shuffling**: Groups may span multiple partitions, requiring data movement\n",
    "- **Memory management**: Large groups might not fit in worker memory  \n",
    "- **Load balancing**: Uneven group sizes can create worker imbalances\n",
    "- **Combinable aggregations**: Some operations (like mean) require careful handling of partial results\n",
    "\n",
    "### Humidity-Temperature Correlation Analysis\n",
    "\n",
    "This operation computes the mean temperature for each humidity level:\n",
    "\n",
    "```python\n",
    "df.TempOut.groupby(df.HumOut).mean().compute()\n",
    "```\n",
    "\n",
    "**Behind the Scenes:**\n",
    "1. **Partial aggregation**: Each partition computes sums and counts locally\n",
    "2. **Data shuffling**: Partial results are combined across partitions by humidity level\n",
    "3. **Final aggregation**: Final means computed from combined sums and counts\n",
    "4. **Result collection**: Final results returned as pandas Series\n",
    "\n",
    "**Performance Note**: This creates a result with potentially 100+ humidity values, which is why we use `.compute()` to materialize the full result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac5275fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "HumOut",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TempOut",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4833e940-fecc-4be7-8f60-b932f33a6129",
       "rows": [
        [
         "-1",
         null
        ],
        [
         "23",
         "20.9"
        ],
        [
         "24",
         "20.55"
        ],
        [
         "25",
         "20.233333333333334"
        ],
        [
         "26",
         "19.75"
        ],
        [
         "28",
         "18.544444444444444"
        ],
        [
         "29",
         "19.316666666666666"
        ],
        [
         "30",
         "19.58235294117647"
        ],
        [
         "31",
         "21.533333333333335"
        ],
        [
         "32",
         "22.69047619047619"
        ],
        [
         "33",
         "25.69333333333333"
        ],
        [
         "34",
         "24.32"
        ],
        [
         "35",
         "25.11935483870968"
        ],
        [
         "36",
         "23.775"
        ],
        [
         "37",
         "22.683333333333334"
        ],
        [
         "38",
         "20.46"
        ],
        [
         "39",
         "20.498333333333335"
        ],
        [
         "40",
         "21.57017543859649"
        ],
        [
         "41",
         "21.735526315789475"
        ],
        [
         "42",
         "19.444660194174755"
        ],
        [
         "43",
         "19.789423076923075"
        ],
        [
         "44",
         "20.946376811594202"
        ],
        [
         "45",
         "20.20344827586207"
        ],
        [
         "46",
         "19.722627737226276"
        ],
        [
         "47",
         "19.270807453416147"
        ],
        [
         "48",
         "19.385714285714286"
        ],
        [
         "49",
         "19.082142857142856"
        ],
        [
         "50",
         "19.899324324324322"
        ],
        [
         "51",
         "18.941139240506327"
        ],
        [
         "52",
         "18.73109756097561"
        ],
        [
         "53",
         "19.742346938775512"
        ],
        [
         "54",
         "18.211042944785277"
        ],
        [
         "55",
         "18.963684210526317"
        ],
        [
         "56",
         "18.055113636363636"
        ],
        [
         "57",
         "18.703125"
        ],
        [
         "58",
         "17.03253012048193"
        ],
        [
         "59",
         "15.842285714285715"
        ],
        [
         "60",
         "15.898369565217392"
        ],
        [
         "61",
         "17.342944785276075"
        ],
        [
         "62",
         "15.45906432748538"
        ],
        [
         "63",
         "14.39665071770335"
        ],
        [
         "64",
         "14.686915887850468"
        ],
        [
         "65",
         "15.820560747663551"
        ],
        [
         "66",
         "14.566972477064219"
        ],
        [
         "67",
         "14.33093220338983"
        ],
        [
         "68",
         "13.627188940092166"
        ],
        [
         "69",
         "14.311165048543689"
        ],
        [
         "70",
         "14.439748953974895"
        ],
        [
         "71",
         "13.540909090909091"
        ],
        [
         "72",
         "12.742788461538462"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 78
       }
      },
      "text/plain": [
       "HumOut\n",
       "-1            NaN\n",
       " 23     20.900000\n",
       " 24     20.550000\n",
       " 25     20.233333\n",
       " 26     19.750000\n",
       "          ...    \n",
       " 96      6.606855\n",
       " 97      8.263484\n",
       " 98      8.850829\n",
       " 99     10.263918\n",
       " 100    15.185714\n",
       "Name: TempOut, Length: 78, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TempOut.groupby(df.HumOut).mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1a466",
   "metadata": {},
   "source": [
    "### Complex GroupBy Computation Graph\n",
    "\n",
    "**Uncomment to visualize the GroupBy task graph:**\n",
    "\n",
    "```python\n",
    "df.TempOut.groupby(df.HumOut).mean().visualize(engine='cytoscape')\n",
    "```\n",
    "\n",
    "**What you'll see in the visualization:**\n",
    "- **Multiple stages**: Partial aggregation → shuffle → final aggregation  \n",
    "- **Data dependencies**: How results from different partitions are combined\n",
    "- **Communication patterns**: Data movement between workers\n",
    "- **Optimization opportunities**: Potential bottlenecks in the computation\n",
    "\n",
    "**Complex GroupBy Pattern**: Notice how this graph is more intricate than simple filtering operations, showing the distributed nature of aggregation computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a962a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.TempOut.groupby(df.HumOut).mean().visualize(engine='cytoscape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c2325",
   "metadata": {},
   "source": [
    "## Advanced Computation Challenges\n",
    "\n",
    "### 🎯 **Challenge 1: Multi-Stage Computation Optimization**\n",
    "\n",
    "**Objective**: Build and optimize a complex computation graph involving multiple operations.\n",
    "\n",
    "**Task**: Create a computation that:\n",
    "1. Filters data for valid temperature and humidity readings\n",
    "2. Creates temperature categories (cold, mild, warm, hot)\n",
    "3. Computes statistics for each category\n",
    "4. Finds correlations between variables\n",
    "\n",
    "```python\n",
    "# TODO: Implement complex multi-stage computation\n",
    "# Step 1: Filter valid data\n",
    "# valid_data = df[(df.TempOut > -50) & (df.TempOut < 50) & (df.HumOut > 0) & (df.HumOut <= 100)]\n",
    "\n",
    "# Step 2: Create temperature categories\n",
    "# def categorize_temp(temp):\n",
    "#     if temp < 0: return 'cold'\n",
    "#     elif temp < 15: return 'mild'  \n",
    "#     elif temp < 25: return 'warm'\n",
    "#     else: return 'hot'\n",
    "\n",
    "# Step 3: Apply categorization and compute statistics\n",
    "# temp_categories = valid_data.TempOut.apply(categorize_temp, meta=('TempOut', 'object'))\n",
    "# category_stats = valid_data.groupby(temp_categories).agg({\n",
    "#     'TempOut': ['mean', 'std', 'count'],\n",
    "#     'HumOut': ['mean', 'std'], \n",
    "#     'WindSpeed': 'mean'\n",
    "# }).compute()\n",
    "```\n",
    "\n",
    "**Learning Objectives**:\n",
    "- Practice chaining multiple Dask operations\n",
    "- Understand when to use `.compute()` vs keeping operations lazy\n",
    "- Learn about the `meta` parameter for custom functions\n",
    "\n",
    "### 🧮 **Challenge 2: Custom Aggregation Functions**\n",
    "\n",
    "**Objective**: Implement custom aggregation functions that work efficiently with Dask's distributed computing model.\n",
    "\n",
    "**Task**: Create a custom function to compute the \"weather comfort index\" based on temperature and humidity:\n",
    "\n",
    "```python\n",
    "# TODO: Implement custom aggregation\n",
    "# def comfort_index(temp_series, humidity_series):\n",
    "#     \"\"\"\n",
    "#     Compute comfort index: higher values = more comfortable\n",
    "#     Formula: 100 - abs(temp - 22) - abs(humidity - 45)\n",
    "#     \"\"\"\n",
    "#     temp_penalty = np.abs(temp_series - 22)  # Optimal temp: 22°C\n",
    "#     humidity_penalty = np.abs(humidity_series - 45)  # Optimal humidity: 45%\n",
    "#     return 100 - temp_penalty - humidity_penalty\n",
    "\n",
    "# Apply custom aggregation\n",
    "# df['comfort'] = comfort_index(df.TempOut, df.HumOut) \n",
    "# monthly_comfort = df.comfort.resample('M', on='datetime_column').mean()\n",
    "```\n",
    "\n",
    "**Advanced**: Implement this as a proper Dask aggregation with proper chunking and combining functions.\n",
    "\n",
    "### ⚡ **Challenge 3: Performance Profiling and Optimization**\n",
    "\n",
    "**Objective**: Profile and optimize Dask computations for maximum performance.\n",
    "\n",
    "**Tasks**:\n",
    "\n",
    "1. **Compare operation strategies:**\n",
    "```python\n",
    "# TODO: Compare these approaches and measure performance\n",
    "# Approach 1: Chain operations with intermediate .compute()\n",
    "# result1 = df[df.HumOut > 50].compute().TempOut.mean()\n",
    "\n",
    "# Approach 2: Keep everything lazy until final result  \n",
    "# result2 = df[df.HumOut > 50].TempOut.mean().compute()\n",
    "```\n",
    "\n",
    "2. **Partition optimization:**\n",
    "```python\n",
    "# TODO: Experiment with different partitioning strategies\n",
    "# Check current partition sizes: df.map_partitions(len).compute()\n",
    "# Repartition for optimal performance: df_repart = df.repartition(partition_size=\"100MB\")\n",
    "```\n",
    "\n",
    "3. **Memory usage profiling:**\n",
    "```python\n",
    "# TODO: Monitor memory usage during computation\n",
    "# from dask.diagnostics import ProgressBar, ResourceProfiler\n",
    "# with ResourceProfiler() as rprof:\n",
    "#     with ProgressBar():\n",
    "#         result = your_complex_computation.compute()\n",
    "```\n",
    "\n",
    "### 🏆 **Master Challenge: Production-Ready Analytics Pipeline**\n",
    "\n",
    "**Objective**: Build a complete analytics pipeline demonstrating production-ready Dask patterns.\n",
    "\n",
    "**Requirements**:\n",
    "- Implement error handling for computation failures\n",
    "- Create modular functions for different analysis components  \n",
    "- Add progress monitoring and logging\n",
    "- Include data validation steps\n",
    "- Optimize for both memory usage and computation time\n",
    "- Document performance characteristics and scaling behavior\n",
    "\n",
    "**Example Pipeline Structure**:\n",
    "```python\n",
    "# TODO: Build complete analytics pipeline\n",
    "# def validate_data(df):\n",
    "#     \"\"\"Validate data quality before processing\"\"\"\n",
    "#     pass\n",
    "\n",
    "# def compute_weather_statistics(df):\n",
    "#     \"\"\"Core analytics computation\"\"\"  \n",
    "#     pass\n",
    "\n",
    "# def export_results(results, format='hdf5'):\n",
    "#     \"\"\"Export results in optimized format\"\"\"\n",
    "#     pass\n",
    "\n",
    "# # Main pipeline\n",
    "# pipeline = df.pipe(validate_data).pipe(compute_weather_statistics)\n",
    "# results = pipeline.compute()\n",
    "# export_results(results)\n",
    "```\n",
    "\n",
    "## 🎓 **Key Takeaways**\n",
    "\n",
    "### **Computational Strategies**\n",
    "1. **Lazy First**: Build entire computation graphs before triggering execution\n",
    "2. **Visualization**: Always visualize complex graphs to understand performance characteristics  \n",
    "3. **Memory Planning**: Reserve 2-3x expected result size for intermediate computations\n",
    "4. **Strategic .compute()**: Only materialize results when necessary for downstream operations\n",
    "\n",
    "### **Performance Optimization**\n",
    "- **Predicate Pushdown**: Apply filters as early as possible in computation graphs\n",
    "- **Partition Awareness**: Understand how operations interact with data partitioning\n",
    "- **Custom Functions**: Use proper `meta` parameters for user-defined functions\n",
    "- **Resource Monitoring**: Profile memory and CPU usage to identify bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955acfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
