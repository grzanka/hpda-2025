{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac16ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da22ada",
   "metadata": {},
   "source": [
    "# Python List Memory Model \n",
    "\n",
    "This notebook explores how Python lists manage memory allocation and growth. \n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "**Dynamic Arrays**: Python lists are implemented as dynamic arrays that can grow and shrink during runtime.\n",
    "\n",
    "**Over-allocation**: Python pre-allocates extra memory slots to minimize the frequency of expensive memory reallocations.\n",
    "\n",
    "**Amortized O(1) Append**: While individual append operations might trigger expensive reallocations, the average cost remains constant due to the over-allocation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f39d0e",
   "metadata": {},
   "source": [
    "## Establishing Memory Baseline\n",
    "\n",
    "Before we start creating large data structures, let's check how much RAM is available on our system. This gives us a baseline to understand the impact of our operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ea388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available RAM: 3.33 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Available RAM: {psutil.virtual_memory().available / (1024 ** 3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b21ee9",
   "metadata": {},
   "source": [
    "## Creating a Large List: Initial Memory Allocation\n",
    "\n",
    "Now we'll create a list with 20 million integers. Few facts:\n",
    "\n",
    "1. **Memory per element**: Each integer in Python uses more memory than you might expect.\n",
    "2. **List overhead**: Python lists store pointers (references) to objects, not the objects themselves.\n",
    "3. **Contiguous pointers**: The pointers are stored one-by-one in a contiguous block of memory, but the actual integer objects may be scattered throughout memory.\n",
    "4. **Performance impact**: Accessing list elements is fast because pointer access is efficient, but scattered integer objects can lead to less efficient CPU caching compared to storing raw data contiguously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5f334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_list = list(range(20_000_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed55e9c",
   "metadata": {},
   "source": [
    "### Measuring List Memory Usage\n",
    "\n",
    "The `sys.getsizeof()` function returns the size of the list object itself (the container), not including the memory used by the individual elements. For a list of integers, this measures:\n",
    "\n",
    "- The list structure overhead\n",
    "- Space for storing references/pointers to the integer objects\n",
    "- Any over-allocated space for future growth\n",
    "\n",
    "**Expected behavior**: A list of 20 million integers should use approximately 150-200 MB of RAM, significantly more than the theoretical minimum due to Python's object model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "568341b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used by big_list: 152.588 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory used by big_list: {sys.getsizeof(big_list) / (1024 ** 2):.3f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50608c39",
   "metadata": {},
   "source": [
    "## Understanding List Growth: The Append Operation\n",
    "\n",
    "When we append elements to a Python list, the memory doesn't grow linearly. Instead, Python uses a smart over-allocation strategy:\n",
    "\n",
    "### Python's Growth Strategy\n",
    "- **Small lists**: Grow by 4 elements at a time\n",
    "- **Medium lists**: Grow by approximately 1/8 of current size + 3\n",
    "- **Large lists**: Grow by approximately 1/16 of current size + 3\n",
    "\n",
    "This strategy ensures that:\n",
    "1. **Amortized O(1) performance**: Most append operations are fast\n",
    "2. **Memory efficiency**: Not too much memory is wasted\n",
    "3. **Predictable behavior**: Growth pattern is consistent\n",
    "\n",
    "Let's observe this behavior by appending elements one by one and watching when memory reallocations occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5409a261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used by big_list after appending one element: 171.661 MB\n"
     ]
    }
   ],
   "source": [
    "# add one integer at the end of the list, check its size and memory usage\n",
    "big_list.append(1)\n",
    "print(f\"Memory used by big_list after appending one element: {sys.getsizeof(big_list) / (1024 ** 2):.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879176b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used by big_list after appending one element: 171.661 MB\n"
     ]
    }
   ],
   "source": [
    "# add one integer at the end of the list, check its size and memory usage\n",
    "big_list.append(1)\n",
    "print(f\"Memory used by big_list after appending one element: {sys.getsizeof(big_list) / (1024 ** 2):.3f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1603e37b",
   "metadata": {},
   "source": [
    "### Observing Memory Reallocation Pattern\n",
    "\n",
    "The following loop demonstrates Python's list growth strategy in action. Notice that:\n",
    "\n",
    "1. **Memory doesn't grow with every append**: Most operations reuse existing allocated space\n",
    "2. **Growth happens in chunks**: When reallocation occurs, significant additional memory is allocated\n",
    "3. **Growth rate decreases**: As the list gets larger, the relative growth rate decreases\n",
    "\n",
    "**Warning**: This loop will double the size of your list, so it may take a while and use substantial memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92fb33e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used after appending element 2500002: 193.119 MB, added 21.458 MB\n",
      "Memory used after appending element 5312506: 217.259 MB, added 24.140 MB\n",
      "Memory used after appending element 8476574: 244.416 MB, added 27.157 MB\n",
      "Memory used after appending element 12036150: 274.969 MB, added 30.552 MB\n",
      "Memory used after appending element 16040674: 309.340 MB, added 34.371 MB\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(big_list)):\n",
    "    size_of_big_list = sys.getsizeof(big_list)\n",
    "    big_list.append(i)\n",
    "    if size_of_big_list != sys.getsizeof(big_list):\n",
    "        print(f\"Memory used after appending element {i}: {sys.getsizeof(big_list) / (1024 ** 2):.3f} MB, added {(sys.getsizeof(big_list) - size_of_big_list) / 1024**2:.3f} MB\")\n",
    "        size_of_big_list = sys.getsizeof(big_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfd4dd9",
   "metadata": {},
   "source": [
    "## Exercise: Growing a List to 10 GB\n",
    "\n",
    "**Your Task**: Implement code that grows the `big_list` until it reaches approximately 10 GB of memory usage. Print the memory usage each time it increases significantly.\n",
    "\n",
    "### What to Observe:\n",
    "1. **Growth pattern**: How much memory is added with each reallocation?\n",
    "2. **Performance**: Does the append operation get slower as the list grows?\n",
    "3. **System impact**: Monitor your system's available memory during the process\n",
    "\n",
    "### Implementation Hints:\n",
    "- Use a while loop that continues until the list reaches 10 GB\n",
    "- Track the previous memory size to detect when reallocations occur\n",
    "- Consider the performance implications - this may take considerable time!\n",
    "- Be prepared to interrupt the process if your system runs low on memory\n",
    "\n",
    "### Safety Note:\n",
    "**Caution**: This exercise will consume approximately 10 GB of RAM. Ensure your system has sufficient memory available before running this code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaffb424",
   "metadata": {},
   "source": [
    "## Writing Data to File: Memory vs Storage\n",
    "\n",
    "This final section demonstrates writing our list to a CSV file. This operation highlights important concepts:\n",
    "\n",
    "### Memory vs Disk Storage:\n",
    "- **In-memory representation**: Our list occupies significant RAM due to Python object overhead\n",
    "- **File representation**: Is it true that the same data requires much less disk space when stored as text ?\n",
    "- **Serialization overhead**: Converting Python objects to text format takes time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895c31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('some.csv', 'w', newline='') as f:\n",
    "    for row in big_list:\n",
    "        f.write(f\"{row}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be148ee7",
   "metadata": {},
   "source": [
    "## Summary: Key Takeaways\n",
    "\n",
    "Through this tutorial, you've learned about Python's list memory model:\n",
    "\n",
    "### Key Insights:\n",
    "1. **Over-allocation Strategy**: Python lists pre-allocate extra memory to minimize expensive reallocations\n",
    "2. **Growth Pattern**: Lists grow by increasingly smaller relative amounts as they get larger\n",
    "3. **Memory Overhead**: Python objects have significant memory overhead compared to raw data\n",
    "4. **Performance Trade-offs**: Memory over-allocation trades space for time efficiency\n",
    "\n",
    "### Practical Implications:\n",
    "- **Large datasets**: Consider alternatives like NumPy arrays or databases for very large datasets\n",
    "- **Memory planning**: Account for Python's memory overhead when estimating resource requirements\n",
    "\n",
    "### Next Steps:\n",
    "In the following notebooks, we'll explore more memory-efficient alternatives like NumPy arrays and learn about tools like Dask for handling datasets that don't fit in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2560870",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
